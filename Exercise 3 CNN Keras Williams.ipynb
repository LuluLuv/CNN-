{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\willi10l\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\willi10l\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow)\n",
      "Requirement already satisfied: numpy>=1.12.1 in c:\\users\\willi10l\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow)\n",
      "Requirement already satisfied: protobuf>=3.3.0 in c:\\users\\willi10l\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow)\n",
      "Requirement already satisfied: tensorflow-tensorboard<0.5.0,>=0.4.0rc1 in c:\\users\\willi10l\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow)\n",
      "Requirement already satisfied: enum34>=1.1.6 in c:\\users\\willi10l\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\willi10l\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow)\n",
      "Requirement already satisfied: setuptools in c:\\users\\willi10l\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\setuptools-27.2.0-py3.6.egg (from protobuf>=3.3.0->tensorflow)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in c:\\users\\willi10l\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow)\n",
      "Requirement already satisfied: html5lib==0.9999999 in c:\\users\\willi10l\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\willi10l\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow)\n",
      "Requirement already satisfied: bleach==1.5.0 in c:\\users\\willi10l\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Keras\n",
      "  Downloading Keras-2.1.3-py2.py3-none-any.whl (319kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\willi10l\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from Keras)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\willi10l\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from Keras)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\willi10l\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from Keras)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\willi10l\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from Keras)\n",
      "Installing collected packages: Keras\n",
      "Successfully installed Keras-2.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras import optimizers\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /notebooks/data/MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /notebooks/data/MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /notebooks/data/MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /notebooks/data/MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/notebooks/data/MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "Training set (55000, 784) (55000, 10)\n",
      "Validation set (5000, 784) (5000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.validation.labels[:1])\n",
    "print('Training set', mnist.train.images.shape, mnist.train.labels.shape)\n",
    "print('Validation set', mnist.validation.images.shape, mnist.validation.labels.shape)\n",
    "print('Test set', mnist.test.images.shape, mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 47,410\n",
      "Trainable params: 47,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr=.003)\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'ep10-1y4-1size50-keras'\n",
    "log_dir = '/notebooks/data/demo' + run_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 3s 63us/step - loss: 0.3043 - acc: 0.9083 - val_loss: 0.1500 - val_acc: 0.9572\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 3s 54us/step - loss: 0.1443 - acc: 0.9559 - val_loss: 0.1422 - val_acc: 0.9564\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 3s 57us/step - loss: 0.1110 - acc: 0.9652 - val_loss: 0.0967 - val_acc: 0.9700\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 3s 56us/step - loss: 0.0928 - acc: 0.9711 - val_loss: 0.1302 - val_acc: 0.9634\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0841 - acc: 0.9744 - val_loss: 0.0979 - val_acc: 0.9706\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 3s 56us/step - loss: 0.0708 - acc: 0.9777 - val_loss: 0.1227 - val_acc: 0.9660\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 4s 71us/step - loss: 0.0671 - acc: 0.9788 - val_loss: 0.1154 - val_acc: 0.9668\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 4s 68us/step - loss: 0.0622 - acc: 0.9805 - val_loss: 0.1139 - val_acc: 0.9728\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 4s 68us/step - loss: 0.0573 - acc: 0.9817 - val_loss: 0.1000 - val_acc: 0.9720\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 3s 61us/step - loss: 0.0525 - acc: 0.9833 - val_loss: 0.0941 - val_acc: 0.9734\n"
     ]
    }
   ],
   "source": [
    "network_history = model.fit(mnist.train.images, mnist.train.labels, batch_size=100, epochs=10, verbose=1,\n",
    "validation_data=(mnist.validation.images, mnist.validation.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
